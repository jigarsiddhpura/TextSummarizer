{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyOjGTrzvr/bFGwIwU1+4k17",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/jigarsiddhpura/TextSummarizer/blob/main/TextSummarizer.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# !pip install -U pip setuptools wheel\n",
        "# !pip install -U spacy\n",
        "# !python -m spacy download en_core_web_lg"
      ],
      "metadata": {
        "id": "t2g5F0LaJ2km"
      },
      "execution_count": 100,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 87,
      "metadata": {
        "id": "x138av59JdQ8"
      },
      "outputs": [],
      "source": [
        "import spacy\n",
        "nlp = spacy.load(\"en_core_web_lg\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from spacy.lang.en.stop_words import STOP_WORDS\n",
        "from string import punctuation\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "import numpy as np\n",
        "from heapq import nlargest\n"
      ],
      "metadata": {
        "id": "6A6WH6DRNtZV"
      },
      "execution_count": 110,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "document = \"Machine learning (ML) is the scientific study of algorithms and statistical models that computer systems use to progressively improve their performance on a specific task. Machine learning algorithms build a mathematical model of sample data, known as “training data”, in order to make predictions or decisions without being explicitly programmed to perform the task. Machine learning algorithms are used in the applications of email filtering, detection of network intruders, and computer vision, where it is infeasible to develop an algorithm of specific instructions for performing the task. Machine learning is closely related to computational statistics, which focuses on making predictions using computers. The study of mathematical optimization delivers methods, theory and application domains to the field of machine learning. Data mining is a field of study within machine learning and focuses on exploratory data analysis through unsupervised learning. In its application across business problems, machine learning is also referred to as predictive analytics.\""
      ],
      "metadata": {
        "id": "vkTAPUHRL7dF"
      },
      "execution_count": 89,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "doc = nlp(document)"
      ],
      "metadata": {
        "id": "pv3jFoPkJsQT"
      },
      "execution_count": 90,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "keywords = []\n",
        "stopWords = list(STOP_WORDS)\n",
        "stopWords.remove(\"not\")\n",
        "pos_tag = ['NOUN','VERB','ADJ','PROPN']\n",
        "\n",
        "for token in doc:\n",
        "  if(token.text in stopWords or token.text in punctuation):\n",
        "    continue\n",
        "  if(token.pos_ in pos_tag):\n",
        "    keywords.append(token.text)\n",
        "  "
      ],
      "metadata": {
        "id": "lcXAhZg1My0F"
      },
      "execution_count": 115,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sentences = [sent for sent in doc.sents]\n",
        "processed_sentences = []\n",
        "\n",
        "for sent in sentences:\n",
        "  processed_sent = \" \".join([token.lemma_ for token in sent if token.pos_ in pos_tag if not token.text in stopWords and not token.is_punct])\n",
        "  processed_sentences.append(processed_sent)"
      ],
      "metadata": {
        "id": "w0WtzQspS44I"
      },
      "execution_count": 116,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "vectorizer = TfidfVectorizer()\n",
        "tf_idf = vectorizer.fit_transform(processed_sentences)"
      ],
      "metadata": {
        "id": "w06R_veoTn5K"
      },
      "execution_count": 117,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tf_idf"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jl3KSwzVUwUx",
        "outputId": "b8bee4db-38f9-446d-abe9-7e5b7fcc75e2"
      },
      "execution_count": 118,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<7x57 sparse matrix of type '<class 'numpy.float64'>'\n",
              "\twith 86 stored elements in Compressed Sparse Row format>"
            ]
          },
          "metadata": {},
          "execution_count": 118
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sentence_scores = tf_idf.sum(axis=1)\n",
        "sentence_scores"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "W9UnG2NwU7Vy",
        "outputId": "f65c5695-1af7-4ea7-f92e-00467a9b54c1"
      },
      "execution_count": 119,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "matrix([[3.79800107],\n",
              "        [3.83103784],\n",
              "        [3.99312046],\n",
              "        [2.89792417],\n",
              "        [3.2158053 ],\n",
              "        [3.0153618 ],\n",
              "        [2.71758319]])"
            ]
          },
          "metadata": {},
          "execution_count": 119
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "weighted_column_indices = np.argsort(sentence_scores, axis=0)\n",
        "print(\"Sorted row indices:\", weighted_column_indices)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cowLCvIfbHMT",
        "outputId": "e90b97fb-8af9-4bbc-ca02-81685b4b41ef"
      },
      "execution_count": 120,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sorted row indices: [[6]\n",
            " [3]\n",
            " [5]\n",
            " [4]\n",
            " [0]\n",
            " [1]\n",
            " [2]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "weighted_indices = np.ravel(weighted_column_indices)\n",
        "weighted_indices"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "S0SbqcmxcxY8",
        "outputId": "7ac026a2-feda-4265-d7c0-b6038db5be68"
      },
      "execution_count": 121,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([6, 3, 5, 4, 0, 1, 2])"
            ]
          },
          "metadata": {},
          "execution_count": 121
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "TOP_SENT_COUNT = 5"
      ],
      "metadata": {
        "id": "l3erzjCElMtC"
      },
      "execution_count": 122,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "top_sentences = []\n",
        "for index in weighted_indices[-TOP_SENT_COUNT:]:\n",
        "  top_sentences.append(processed_sentences[index])"
      ],
      "metadata": {
        "id": "DFrDMjxygA2e"
      },
      "execution_count": 123,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "summarized_sentences = nlargest(3,top_sentences)"
      ],
      "metadata": {
        "id": "_kCtEKbemGpf"
      },
      "execution_count": 124,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "summarized_sentences"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "N5M-VQ6dnOjG",
        "outputId": "6bbcf584-655c-4ee0-ce32-b4019bd131f2"
      },
      "execution_count": 125,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['study mathematical optimization deliver method theory application domain field machine learning',\n",
              " 'machine learning algorithm build mathematical model sample datum know training datum order prediction decision program perform task',\n",
              " 'machine learning algorithm application email filtering detection network intruder computer vision infeasible develop algorithm specific instruction perform task']"
            ]
          },
          "metadata": {},
          "execution_count": 125
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Define a function to process each sentence\n",
        "def process_sentence(sentence):\n",
        "    # Parse the sentence using Spacy's sentence segmentation\n",
        "    doc = nlp(sentence)\n",
        "\n",
        "    # Lemmatize the words in the sentence and join them back into a string\n",
        "    lemmas = [token.lemma_ for token in doc]\n",
        "    sentence_text = ' '.join(lemmas)\n",
        "\n",
        "    # Construct a grammatically correct sentence from the lemmatized words\n",
        "    sentence_doc = nlp(sentence_text)\n",
        "    sentence_text = ''\n",
        "    for i, token in enumerate(sentence_doc):\n",
        "        # Add spaces between words\n",
        "        if i > 0:\n",
        "            sentence_text += ' '\n",
        "        # Add determiners to nouns if necessary\n",
        "        if token.pos_ == 'NOUN' and token.dep_ != 'compound':\n",
        "            sentence_text += 'a '\n",
        "        # Add the word to the sentence\n",
        "        sentence_text += token.text\n",
        "    # Capitalize the first letter of the sentence\n",
        "    sentence_text = sentence_text.capitalize()\n",
        "    # Add a period to the end of the sentence\n",
        "    sentence_text += '.'\n",
        "    return sentence_text\n"
      ],
      "metadata": {
        "id": "dScvY0nDqJJ-"
      },
      "execution_count": 127,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "processed_sentences = [process_sentence(sentence) for sentence in summarized_sentences]\n",
        "\n",
        "# Print the results\n",
        "for sentence in processed_sentences:\n",
        "    print(sentence)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fBWrTtyprzwJ",
        "outputId": "cac63bc4-59d7-446c-ae85-c84482eb3345"
      },
      "execution_count": 128,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Study mathematical a optimization deliver method theory application domain field a machine learn.\n",
            "Machine learning a algorithm build mathematical model sample a datum know training datum order prediction decision a program perform a task.\n",
            "Machine learning algorithm application email filter detection network intruder computer a vision infeasible develop a algorithm specific a instruction a perform a task.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "EbCXDlEcsNAB"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}